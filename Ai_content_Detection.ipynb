{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDkMs1TWF6GU"
      },
      "source": [
        "#####Run:\n",
        "\n",
        "*  Dependencies\n",
        "*  Load predictor and run\n",
        "*  Plagiarism-v2\n",
        "*  Statistical BERT\n",
        "*  WebUI with GRADIO\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL4bVBLJPW_9"
      },
      "source": [
        "# Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbfJhpKAzzyk",
        "outputId": "62d80e0f-8163-47b4-edd8-a14b496dcf46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ktrain\n",
            "  Downloading ktrain-0.41.3.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.0.3)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ktrain) (24.0)\n",
            "Collecting langdetect (from ktrain)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.3.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (5.2.0)\n",
            "Collecting syntok>1.3.3 (from ktrain)\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting tika (from ktrain)\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from ktrain) (4.40.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.1.99)\n",
            "Collecting keras_bert>=0.86.0 (from ktrain)\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh (from ktrain)\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_bert>=0.86.0->ktrain) (1.25.2)\n",
            "Collecting keras-transformer==0.40.0 (from keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0 (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2024.1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.10/dist-packages (from syntok>1.3.3->ktrain) (2023.12.25)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2024.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->ktrain) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers->ktrain) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers->ktrain) (4.11.0)\n",
            "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, tika\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.41.3-py3-none-any.whl size=25316960 sha256=65fee5f89dbac75cba4dcffaec1338da6b203e0de15f39c483696aa86f6e60bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/76/11/5b953090eebf531f660948a30cd26e70260619f6480f186a5a\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33500 sha256=9b4c3c3a4ea4616b56eca659b4c78b9c16170c13c86e30c0cdd846fd003252fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/0c/04/646b6fdf6375911b42c8d540a8a3fda8d5d77634e5dcbe7b26\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12286 sha256=ee1b227705ad52265169dab9bbfe01c0578e3d3ac055a616a5b7309bad8d7bdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/cb/22/75a0ad376129177f7c95c0d91331a18f5368fd657f4035ba7c\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3944 sha256=efa956653fc9085b1d9503e75a630fa48b1fc8b0230ee9e5ce8255f85171fe23\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/32/c7/fd35d0d1b840a6c7cbd4343f808d10d0f7b87d271a4dbe796f\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4654 sha256=326003866fbe2c2e32effff4cea9e1ec411f254a0cc6199b6973f7e12c13d8ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/3a/4b/21db23c0cc56c4b219616e181f258eb7c57d36cc5d056fae9a\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14976 sha256=24aba6b8504b2a3fcd4f1d683eda115f4389a3b424cc1c9f3c805a93ab83b233\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/23/4b/06d7ae21714f70fcc25b48f972cc8e5e7f4b6b764a038b509d\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6945 sha256=1b6288019b44a085813403c9b0f459f167a1747d133830f02145c33a226f6ab3\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/07/1b/b1ca47b6ac338554b75c8f52c54e6a2bfbe1b07d79579979a4\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4969 sha256=9c1f929594d8bbd88f0bf1f260f0df192e90aef90eb2b0f734565782b5241bc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/6a/04/d1706a53b23b2cb5f9a0a76269bf87925daa1bca09eac01b21\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18894 sha256=f9e3a356427f3efe1acd1ec87372b33dbaf17bb3a06778d9d5d7602f8d3f2a1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=4fa2d3442e52f49327714e67302922e80018f9ad436a673c93053d28bece5f4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32621 sha256=d976bc5911d14117df87b6314e5618bd1d97dd86459619f32aa28aba34c3632e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect tika\n",
            "Installing collected packages: whoosh, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, tika, keras-multi-head, keras-transformer, keras_bert, ktrain\n",
            "Successfully installed keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.41.3 langdetect-1.0.9 syntok-1.4.4 tika-2.6.0 whoosh-2.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip install ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_164utsrJ6w",
        "outputId": "37c8ecdd-b8f8-4bb1-ac6c-d199e7fc2b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1XDlBtyMipbr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "77TPGE0ZuGzt"
      },
      "outputs": [],
      "source": [
        "!pip -q install transformers\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer,  AutoModelForSequenceClassification\n",
        "import numpy as np\n",
        "# Cosine Similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mojKQfR8prLx"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PEOkOXYv8-zf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import ktrain\n",
        "from ktrain import text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu6jofj4I9jz"
      },
      "source": [
        "# TRAIN PREDICTOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zyunnKf41x1G"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PPirzk_pzL1z"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy8oCOEO0AjH",
        "outputId": "638aa23a-c239-4d3f-b504-66c13e6285a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s8dcsH91puhC"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XLMKCro64MzP"
      },
      "outputs": [],
      "source": [
        "categories = [\"Human\", \"GPT4\", \"GPT3\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "j0jD2vDoK0L3"
      },
      "outputs": [],
      "source": [
        "categories = [\"Human\", \"AI\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "pudt4mj1sa87"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CZZOHuRffRLd"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/alldata (1).csv\", encoding='latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NiOv-wOj0HQz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "a8a8eb76-189b-4612-d377-1de663f89f7b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/gdrive/MyDrive/Minor/final_big_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-a40270a349d3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/Minor/final_big_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/Minor/final_big_dataset.csv'"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"/content/gdrive/MyDrive/Minor/final_big_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "RYD-tGF41PUx",
        "outputId": "b3d6eed5-d669-4a74-f645-360ec3dfb3c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text   \\\n",
              "84                                                  NaN   \n",
              "1902  could begin again. The result was that practic...   \n",
              "2613                                                NaN   \n",
              "2977                                                NaN   \n",
              "3530  without the stirrup, and, with her arms placed...   \n",
              "3640  High-mettled or fretful horses, it is often ne...   \n",
              "2406       by a Platoon Commander holding the most d...   \n",
              "4182                                CONCLUDING REMARKS.   \n",
              "491   April 24th witnessed our first serious bombard...   \n",
              "3189  Having, now, offered our fair readers a slight...   \n",
              "\n",
              "                      domain                name           kind   model  \n",
              "84     CollegeEssay_real_154  Real College Essays  Human-Written  Human  \n",
              "1902  CollegeEssay_real_1972  Real College Essays  Human-Written  Human  \n",
              "2613  CollegeEssay_real_2683  Real College Essays  Human-Written  Human  \n",
              "2977  CollegeEssay_real_3047  Real College Essays  Human-Written  Human  \n",
              "3530  CollegeEssay_real_3600  Real College Essays  Human-Written  Human  \n",
              "3640  CollegeEssay_real_3710  Real College Essays  Human-Written  Human  \n",
              "2406  CollegeEssay_real_2476  Real College Essays  Human-Written  Human  \n",
              "4182  CollegeEssay_real_4252  Real College Essays  Human-Written  Human  \n",
              "491    CollegeEssay_real_561  Real College Essays  Human-Written  Human  \n",
              "3189  CollegeEssay_real_3259  Real College Essays  Human-Written  Human  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7157d45d-f4e4-469b-8fa1-c886ce848774\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>domain</th>\n",
              "      <th>name</th>\n",
              "      <th>kind</th>\n",
              "      <th>model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>NaN</td>\n",
              "      <td>CollegeEssay_real_154</td>\n",
              "      <td>Real College Essays</td>\n",
              "      <td>Human-Written</td>\n",
              "      <td>Human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1902</th>\n",
              "      <td>could begin again. The result was that practic...</td>\n",
              "      <td>CollegeEssay_real_1972</td>\n",
              "      <td>Real College Essays</td>\n",
              "      <td>Human-Written</td>\n",
              "      <td>Human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2613</th>\n",
              "      <td>NaN</td>\n",
              "      <td>CollegeEssay_real_2683</td>\n",
              "      <td>Real College Essays</td>\n",
              "      <td>Human-Written</td>\n",
              "      <td>Human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2977</th>\n",
              "      <td>NaN</td>\n",
              "      <td>CollegeEssay_real_3047</td>\n",
              "      <td>Real College Essays</td>\n",
              "      <td>Human-Written</td>\n",
              "      <td>Human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3530</th>\n",
              "      <td>without the stirrup, and, with her arms placed...</td>\n",
              "      <td>CollegeEssay_real_3600</td>\n",
              "      <td>Real College Essays</td>\n",
              "      <td>Human-Written</td>\n",
              "      <td>Human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3640</th>\n",
              "      <td>High-mettled or fretful horses, it is often ne...</td>\n",
              "      <td>CollegeEssay_real_3710</td>\n",
              "      <td>Real College Essays</td>\n",
              "      <td>Human-Written</td>\n",
              "      <td>Human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406</th>\n",
              "      <td>by a Platoon Commander holding the most d...</td>\n",
              "      <td>CollegeEssay_real_2476</td>\n",
              "      <td>Real College Essays</td>\n",
              "      <td>Human-Written</td>\n",
              "      <td>Human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4182</th>\n",
              "      <td>CONCLUDING REMARKS.</td>\n",
              "      <td>CollegeEssay_real_4252</td>\n",
              "      <td>Real College Essays</td>\n",
              "      <td>Human-Written</td>\n",
              "      <td>Human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>April 24th witnessed our first serious bombard...</td>\n",
              "      <td>CollegeEssay_real_561</td>\n",
              "      <td>Real College Essays</td>\n",
              "      <td>Human-Written</td>\n",
              "      <td>Human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3189</th>\n",
              "      <td>Having, now, offered our fair readers a slight...</td>\n",
              "      <td>CollegeEssay_real_3259</td>\n",
              "      <td>Real College Essays</td>\n",
              "      <td>Human-Written</td>\n",
              "      <td>Human</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7157d45d-f4e4-469b-8fa1-c886ce848774')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7157d45d-f4e4-469b-8fa1-c886ce848774 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7157d45d-f4e4-469b-8fa1-c886ce848774');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ffe32e3e-d7ab-40b1-92c1-483cd77b6b90\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ffe32e3e-d7ab-40b1-92c1-483cd77b6b90')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ffe32e3e-d7ab-40b1-92c1-483cd77b6b90 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"text \",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"could begin again. The result was that practically all the French mines were defensive, and\",\n          \"without the stirrup, and, with her arms placed behind her, while the master holds the long\",\n          \"April 24th witnessed our first serious bombardment. We had already had several somewhat severe\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"CollegeEssay_real_561\",\n          \"CollegeEssay_real_1972\",\n          \"CollegeEssay_real_3710\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name \",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Real College Essays\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kind \",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Human-Written\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Human\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "data.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2y8MwPEDrngE"
      },
      "outputs": [],
      "source": [
        "data.loc[data[\"model\"] == \"GPT4\", \"model\"] = 1\n",
        "data.loc[data[\"model\"] == \"GPT3\", \"model\"] = 1\n",
        "data.loc[data[\"model\"] == \"Human\", \"model\"] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zTDbWqyZuI7u"
      },
      "outputs": [],
      "source": [
        "rows_with_float = data.select_dtypes(include=['float']).any(axis=1)\n",
        "\n",
        "# Drop rows with float values\n",
        "df = data[~rows_with_float]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGIB44Asr-VP",
        "outputId": "a7e217bc-5c16-4b16-fb8b-25e1b2970b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4225 entries, 0 to 4224\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    3783 non-null   object\n",
            " 1   domain  4225 non-null   object\n",
            " 2   name    4225 non-null   object\n",
            " 3   kind    4225 non-null   object\n",
            " 4   model   4225 non-null   object\n",
            "dtypes: object(5)\n",
            "memory usage: 165.2+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6flPLFtlsDfz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f95fc582-b46b-4892-dfaa-69aebf113a53"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'filtered_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ac6e7e3ef4f6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiltered_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'filtered_df' is not defined"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhuwU26TrWNZ",
        "outputId": "f5a497eb-5acc-4a71-b631-a4f02798f077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Labels: ['text ', 'domain', 'name ', 'kind ', 'model']\n"
          ]
        }
      ],
      "source": [
        "print(\"Column Labels:\", data.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jW7LooI_wsCJ"
      },
      "outputs": [],
      "source": [
        "data=data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove extra spaces from column names\n",
        "data.columns = data.columns.str.strip()\n",
        "\n",
        "# Check column names again\n",
        "print(data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irwopyHmXvFV",
        "outputId": "807a0930-90af-4b27-e100-5ef2263f293d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['text', 'domain', 'name', 'kind', 'model'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vAcQoyJg1Xdh"
      },
      "outputs": [],
      "source": [
        "X = data[\"text\"].tolist()\n",
        "y = data[\"model\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "C9ZdzKRd1fd-"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3px40VDOjuuw",
        "outputId": "8a941384-9615-4cab-ac8e-06e4f34dfdd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'keras_rectified_adam'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21\u001b[K\n",
            "Receiving objects: 100% (21/21), 487.03 KiB | 3.99 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ],
      "source": [
        "# install and import Rectified Adam\n",
        "!git clone https://github.com/titu1994/keras_rectified_adam.git\n",
        "!cp keras_rectified_adam/rectified_adam.py .\n",
        "from rectified_adam import RectifiedAdam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dFwI7Ew31kv1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "e6fad173c1fc49d8a1d0d75bb69d9377",
            "be1c4222519946f5aed2797aae00d143",
            "5e7ee55dd21d4e9a81063ebdd0b5216c",
            "18de9987698f4de8992e2a863f805ec8",
            "e2980a8d431b4ab09e4dcd0043fb548c",
            "0d8bf94724c745a79f1721445d18a6dc",
            "3600e11e76274e2e9f1457aa7fac3580",
            "8e8d4b2fa13c4f51abb71459110770ce",
            "b28d7b91170144278ce2c82744a9c9fc",
            "b0d037f1d3e74f628b730797d10c715d",
            "50658b05a7ac422eb738bff8e4acaec1",
            "bea75e877fda4f4ca71f6cb8433bd096",
            "0501e82a58004ee3a530a8dff2bebe62",
            "11bea714c5254ffdacf6b2cd06b75c73",
            "38627e44b7e94e6dafbea30f22f6ad16",
            "b511a2f15be14626bf1cd47d5bae56a5",
            "132e7669bf934e628b1582a5d5bafcdf",
            "fca740794a534e47875a2384e96a1945",
            "b063e6507f1046e6bbd705af9f20b572",
            "d8aa25f41bb74ddaa01f333ca9b0581b",
            "3608152a3fe54c68871adf67f9d5224b",
            "5ce42c931ac54514a438677bc59ce452"
          ]
        },
        "outputId": "65fb2afa-1f55-4907-abf6-6cc4b4ff0a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6fad173c1fc49d8a1d0d75bb69d9377"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bea75e877fda4f4ca71f6cb8433bd096"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = 'distilbert-base-uncased'\n",
        "trans = text.Transformer(model_name, maxlen=512, class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-rectified-adam\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTHPvWADY8xP",
        "outputId": "5ff40e8f-8977-4b6f-ecce-2a466910b08f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-rectified-adam\n",
            "  Downloading keras-rectified-adam-0.20.0.tar.gz (7.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-rectified-adam) (1.25.2)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.10/dist-packages (from keras-rectified-adam) (2.15.0)\n",
            "Building wheels for collected packages: keras-rectified-adam\n",
            "  Building wheel for keras-rectified-adam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-rectified-adam: filename=keras_rectified_adam-0.20.0-py3-none-any.whl size=8255 sha256=248493cab99a35e77b527d6de5be8fdaf9edd85b9649de1e4d672ccee8c79624\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/fe/0f/dcf898210ceef6ae45cea51d3d27765f38bce2b4dc8e88245f\n",
            "Successfully built keras-rectified-adam\n",
            "Installing collected packages: keras-rectified-adam\n",
            "Successfully installed keras-rectified-adam-0.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PgOeKKhYBBN",
        "outputId": "e84cae39-d270-46a5-d789-f330a7a696af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "# build a model and use Rectified Adam\n",
        "import transformers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(20000+1, 50, input_length=400)) # add 1 for padding token\n",
        "    model.add(GlobalAveragePooling1D())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = get_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "PLoHGo3UYmju"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'distilbert-base-uncased'\n",
        "t = text.Transformer(MODEL_NAME, maxlen=500, class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GwZVKfkShDMZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "class_weight = class_weight.compute_class_weight('balanced', classes=np.unique(y_train),y=y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339,
          "referenced_widgets": [
            "1cbaa1bd49cd4660a3748fe97247acf9",
            "54ad8df72c58493d96130fbc3be94093",
            "5cf3549491024976b82f6fef9805cd52",
            "ebe371ebf71c43a584a840d345032cff",
            "bf243e8202be466c82635f1ae6b7a71d",
            "f77e510ce9494260add0a255f5beaae6",
            "71344f97edeb40d583be8f17deebc075",
            "484cf0dc65344bd28f79434577c19192",
            "74b5a0362a3c4f4bbb205c77cbe8cb0c",
            "81d7fe19439f40daadc567a29521a142",
            "1a245cf8b668457cb5805e3f5b035480",
            "e3bdfd4b6bb64d0a9c4e3256d3d55182",
            "69b73f10b2e141d4abd5223c1fc9941e",
            "69c2a79634a14f8a95a939eb5223b9ba",
            "57684074cc3e4bccbf055239f3857ecc",
            "293db33e8ec54102a4a9f73963e6239c",
            "501cdfcdcf904721b0961219efbe9886",
            "c7736b49d12c4faeb8bc7ae08ff2eaf7",
            "6c20b92482d84ec4823bbcdd4515abd7",
            "93975294c6ad45dbb07b7d4862b50e7f",
            "821c177d83ca42a3951a4457f1fd8d63",
            "3e4f59b3f1ea409cb2643a46b6b7eb6a",
            "3814affccfc548589c45199456b3280d",
            "3077523b8e66476a8bf8c2adbec6c55d",
            "8cb0edf2d8d547bdae586c4c27991cd1",
            "70a8b6225d8d4d908100092571bb6c4f",
            "c417ac6f48754a13be42da4a8dae68fd",
            "bf50ddd201a748ba97cddbf051973809",
            "02d73ebe81fa4381940b3dc653663069",
            "5c1a25d5012a4cf0bc8b910fd3331405",
            "42d4d865b5974b0c936adbea15ccc122",
            "f5a42fc4a0694beeb1875769c5dbf7ea",
            "ee56714955d7452e8aeaf2a863cd3957"
          ]
        },
        "id": "ujCIFIB52OQ3",
        "outputId": "ef228e5f-e30f-4417-d269-ebb9ed90b5cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 16\n",
            "\t95percentile : 19\n",
            "\t99percentile : 21\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cbaa1bd49cd4660a3748fe97247acf9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3bdfd4b6bb64d0a9c4e3256d3d55182"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3814affccfc548589c45199456b3280d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 16\n",
            "\t95percentile : 19\n",
            "\t99percentile : 20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_data = t.preprocess_train(X_train, y_train)\n",
        "test_data = t.preprocess_test(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nmLBLJm6jrNb"
      },
      "outputs": [],
      "source": [
        "import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "RicntVuejbIi"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "2la3eIRV2VQ4",
        "outputId": "cf2ef4a7-2fd6-47e8-8046-418f3a86f663"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Could not interpret optimizer identifier: <keras.src.optimizers.legacy.adam.Adam object at 0x7dc79c4d6710>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-5f9c32addc58>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ktrain/text/preprocessor.py\u001b[0m in \u001b[0;36mget_classifier\u001b[0;34m(self, fpath, multilabel, metrics)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_OPT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[0;31m# This argument got renamed, we need to support both versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"steps_per_execution\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparent_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m             super().compile(\n\u001b[0m\u001b[1;32m   1564\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/optimizers/__init__.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m         )\n\u001b[1;32m    333\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;34mf\"Could not interpret optimizer identifier: {identifier}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Could not interpret optimizer identifier: <keras.src.optimizers.legacy.adam.Adam object at 0x7dc79c4d6710>"
          ]
        }
      ],
      "source": [
        "model = trans.get_classifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "0u7XNtnJqrMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dcf9832-dc54-4c1b-af7b-67238654c5ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "# build a model and use Rectified Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(20000+1, 50, input_length=400)) # add 1 for padding token\n",
        "    model.add(GlobalAveragePooling1D())\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=RectifiedAdam(lr=1e-3), metrics=['accuracy'])\n",
        "    return model\n",
        "model = get_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7q2TZZ3iE0O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zTbgfJE2ffo",
        "outputId": "7b4a68f3-a3ce-45ea-bafd-0b5dc033e5ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "/usr/local/lib/python3.10/dist-packages/ktrain/__init__.py:138: UserWarning: ktrain currently only supports legacy optimizers in tensorflow>=2.11 - recompiling your model to use legacy Adam\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "learner = ktrain.get_learner(model, train_data=train_data, val_data=test_data, batch_size=16, optimizer='adam' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "LzYGC1Cc41jg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "ba65c7a8-cd16-459b-9777-89a2290d45df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simulating training for different learning rates... this may take a few moments...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Sequential' object has no attribute 'save_pretrained'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-adc3d4549298>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_plot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ktrain/core.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, lr_mult, max_epochs, class_weight, stop_factor, show_plot, suggest, restore_weights_only, verbose)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0mtemp_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdtemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;31m# compute steps_per_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ktrain/text/learner.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, fpath)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[1;32m    212\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_model_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'save_pretrained'"
          ]
        }
      ],
      "source": [
        "learner.lr_find(show_plot=True, max_epochs = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zOfc_x82kHc"
      },
      "outputs": [],
      "source": [
        "learner.fit_onecycle(1e-4, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLRvbjCZD7go"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6wxq6693jzy"
      },
      "outputs": [],
      "source": [
        "learner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ZJ5mvOUW_h2T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "73625144-fda8-4f28-e8e6-3c5a7cc461ed"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'learner' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-d31abd6ce101>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'learner' is not defined"
          ]
        }
      ],
      "source": [
        "learner.plot('val_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luNU7TVz_v3-"
      },
      "outputs": [],
      "source": [
        "learner.plot('accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "KRySxfixAJ3H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "12a8e2b4-aaff-48bf-93ef-8c7efbcb92c5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'learner' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-2c840d19c36b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'learner' is not defined"
          ]
        }
      ],
      "source": [
        "learner.plot('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "LQDmdiVs3qUa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "835d05af-4238-4a1f-89f8-808e362c72c4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'learner' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-b6cbf8971a1f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_top_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'learner' is not defined"
          ]
        }
      ],
      "source": [
        "learner.view_top_losses(n=5, preproc=trans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl9zCNl53wP7"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc=trans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeFusGz531zz"
      },
      "outputs": [],
      "source": [
        "x = \"The 1998 FIFA World Cup final was the final match of the 32-team 1998 FIFA World Cup, played on 12 July at the Stade de France (pictured) in Paris, France, between defending champions Brazil and hosts France. Before the match, speculation surrounded the fitness of striker Ronaldo, who was at first left out of Brazil's starting line-up, only to be restored before kick-off. France took the lead shortly before the half-hour mark, when Zinedine Zidane outjumped Leonardo to connect with a header from an in-swinging corner from the right taken by Emmanuel Petit. Zidane scored again, with another header from a corner, shortly before half-time to give France a 2–0 lead. Petit then added a third goal in second-half injury time, striking the ball low into the net following a pass by Patrick Vieira, to complete a 3–0 win for France, giving them their first World Cup title.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cWq8CSP33C9"
      },
      "outputs": [],
      "source": [
        "predictor.predict(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU7_wY5JxqhR"
      },
      "outputs": [],
      "source": [
        "predictor.save(\"/content/gdrive/My Drive/Minor/pred_bigdataset.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9t9kiiXCz2F"
      },
      "source": [
        "# Load predictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GImd91mH48s"
      },
      "outputs": [],
      "source": [
        "predictor=ktrain.load_predictor(\"/content/gdrive/MyDrive/pred4.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0Y8KGlaKQoV"
      },
      "outputs": [],
      "source": [
        "x=\"Over the last 20 years or so, digital media has offered a new site for the production, dissemination, and consumption of texts. A proliferation of platforms has led to new forms through which writers share their ideas and create art. Since the earliest ventures into electronic literature, like hypertext stories shared on webpages, the development of Web 2.0 technologies and social media has turned all users into potential creators of content. Texts that emerge often blur the lines between the mundane and the extraordinary. This commentary considers the poetics of contemporary digital texts, objects, and cultures. Influenced by the questions of power, representation, and globalization central to postcolonial studies, posts consider poetics of platform, found poetry online, materiality of electronic literature, and the cultural logic of viral textuality.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB7FMOvdJRXx",
        "outputId": "2ea51771-3c22-4948-d46b-b567d353dd69"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'AI'"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "769i_BmW2YxU"
      },
      "source": [
        "#TEst predictor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2R-tMKgtmJW"
      },
      "outputs": [],
      "source": [
        "x = \"This is quick to compute since the perplexity of each segment can be computed in one forward pass, but serves as a poor approximation of the fully-factorized perplexity and will typically yield a higher (worse) PPL because the model will have less context at most of the prediction steps. Instead, the PPL of fixed-length models should be evaluated with a sliding-window strategy. This involves repeatedly sliding the context window so that the model has more context when making each prediction.\"\n",
        "#^ human\n",
        "y= \"Once upon a time there was an old mother pig who had three little pigs and not enough food to feed them. So when they were old enough, she sent them out into the world to seek their fortunes. The first little pig was very lazy. He didn't want to work at all and he built his house out of straw. The second little pig worked a little bit harder but he was somewhat lazy too and he built his house out of sticks. Then, they sang and danced and played together the rest of the day. The third little pig worked hard all day and built his house with bricks. It was a sturdy house complete with a fine fireplace and chimney. It looked like it could withstand the strongest winds. The next day, a wolf happened to pass by the lane where the three little pigs lived; and he saw the straw house, and he smelled the pig inside. He thought the pig would make a mighty fine meal and his mouth began to water. So he knocked on the door and said:\"\n",
        "#^ human\n",
        "z= '''Sure! Imagine a robot is like a special kind of toy that can move and do things all on its own, just like a superhero! But instead of being made of plastic or stuffed with stuffing, a robot is made of metal and wires.\n",
        "\n",
        "Robots have special parts called sensors and motors that help them see and hear things, and they can use those senses to figure out what's happening around them. Some robots have arms and legs, like a person, and they can pick up things, while others might have wheels and can roll around.\n",
        "\n",
        "The coolest part is that we can tell robots what to do by giving them instructions. They can follow these instructions and do all sorts of tasks, like helping in factories, cleaning our homes, or even exploring outer space!\n",
        "\n",
        "So, a robot is like a smart and helpful friend that can do things for us with the help of its special metal and wires.'''\n",
        "#^ ai\n",
        "a= \"Exploring this field, I discovered that open-source tools and language models enable virtually anyone to create similar innovative tools and services. I encountered various models with distinct capabilities, including stable diffusion and BERT. This realization led me to believe that AI systems, especially large language models and multimodal models, have the potential to revolutionize numerous industries and sectors. Imagine the integration of machine learning and natural speech into robots, or employing multimodal models as the backbone of robotic software. Envision AI generators serving as creative tools or AI being extensively utilized for problem-solving across various domains. The prospects seemed boundless. Subsequently, hearing about Google's DeepMind AI's forecasting abilities, AI's contributions to breakthroughs in cancer research, and advancements in Tesla's self-driving cars further solidified my belief in the transformative power of AI technologies. As I approach the completion of my undergraduate degree, my enthusiasm for AI has only grown stronger. I am eager to delve deeper into this field and expand my knowledge and skills. The Fuse AI Fellowship Program presents an ideal opportunity for me to connect with like-minded individuals who share my passion for AI. Through this program, I hope to enhance my understanding of both foundational and cutting-edge concepts in AI while also expanding my network within the field.\"\n",
        "#^ ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaRG0xOItmJW",
        "outputId": "fc3b8a14-7cbf-426c-ab3f-64bfc8bc0d97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI\n",
            "Human\n",
            "Human\n",
            "AI\n"
          ]
        }
      ],
      "source": [
        "print(predictor.predict(x)) #0=human 1=ai\n",
        "print(predictor.predict(y))\n",
        "print(predictor.predict(z))\n",
        "print(predictor.predict(a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kozFrb2R4KN"
      },
      "outputs": [],
      "source": [
        "test=[]#ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1KtyLEGRsFF"
      },
      "outputs": [],
      "source": [
        "test.append('Toll-like receptors (TLRs) are well-defined pattern recognition receptors responsible for pathogen recognition and induction of innate immune responses. They play an important role in recognition of viral particles and activation of the innate immune system. Activation of TLR pathways leads to secretion of pro-inflammatory cytokines, such as interleukin-1 (IL-1), IL-6, and tumor necrosis factor-α, as well as type 1 interferon. TLRs serve a central role in innate immunity, but they can also modulate cell function in various non-immune cell types including endothelial cells.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bKK7hYRR-Z4"
      },
      "outputs": [],
      "source": [
        "test.append('Tuberculosis has existed in India for several thousand years. The disease was first recognized through a resolution passed in the All India Sanitary Conference held at Madras in 1912. The description of tuberculosis was initially found in India and China as early as 3300 and 2300 years ago, respectively. The TB picture started becoming clear with the introduction of tuberculin testing. India’s response to TB has changed with time and with the increasing sophistication of technology. Responses to TB have evolved, from pre-independence through post-independence to the current WHO-assisted period.')\n",
        "test.append('The Cox proportional hazards regression model is a statistical method used to analyze survival data. It is used to model the relationship between survival time and one or more predictor variables. The model estimates the hazard ratio (HR) of a given endpoint associated with a specific risk factor, which can be either a continuous variable like age and C-reactive protein level or a categorical variable like gender and treatment group. The Cox regression method is considered as an example of semi-parametric models. It is commonly used in medical research for investigating the association between the survival time of patients and one or more predictor variables.')\n",
        "test.append('SARS-CoV-2 infects the respiratory epithelial tissue and activates local innate immune cells to release inflammatory cytokines such as IL-1, IL-6, IL-8, IL-12, TNF-α, and other chemokines. Since proinflammatory cytokines are elevated in severe COVID-19 patients, SARS-CoV-2 seems to activate NF-κB and produces proinflammatory cytokines, which is correlated with COVID-19 pathogenesis. Immune responses to SARS-CoV infection are initiated by the innate immune system, which recognizes pathogens and induces proinflammatory cytokines to trigger the immune response. The immune response is followed by responses of the adaptive immune system consisting of T cells that can directly kill virus-infected cells and B cells that produce pathogen-specific antibodies.')\n",
        "test.append('According to a study published on PubMed, the presence of laminated membrane detachment and/or pericyst degenerative changes is associated with a favorable outcome in asymptomatic univesicular liver hydatids. However, their absence does not necessarily indicate an unfavorable outcome. Hepatic cystic echinococcosis (CE) is composed of two derived layers of membrane: an inner, nucleated, germinal membrane, and an outer, acellular, laminated layer.')\n",
        "test.append('The test-negative case-control study design is a popular approach for estimating vaccine effectiveness (VE) due to its efficiency. However, other biases will occur. In comparing the effectiveness of vaccines, the confounding effects of health care–seeking behavior are reduced. But other biases such as selection bias, information bias, and confounding by indication may still exist.')\n",
        "test.append('Beta-thalassemia is a genetic disorder that is prevalent in Iran. According to a study, the most common mutation of β-Thalassemia among the western parts of the Mediterranean Sea such as Portugal, Spain, and France is Codon 39. This mutation is also the most frequent in Queshm Island, located south of Iran in the Persian Gulf. Another study conducted in Hamadan province, Iran showed that β-thal caused by mutations on the HBB gene is the most common single-gene disorder in the world. The HBB gene mutation was investigated in 41 patients referred to a referral hospital. A third study showed that IVS-I-5 (G > C) was the most common mutation by far accounting for about 80% of all detected β-thal alleles in this region.')\n",
        "test.append('The likelihood ratio (LR) is a semiquantitative measure of the performance of diagnostic tests which indicates how much a diagnostic procedure modifies the probability of disease, and is calculated from the sensitivity and specificity of the test (or directly from the change in probability associated with the test result). The LR can be used to calculate post-test probabilities of disease for patients with positive or negative test results. The LR can be maximized by choosing an appropriate cut-off value for the test result.')\n",
        "test.append('Shannon’s information theory is a mathematical theory that describes the fundamental laws of data compression and error correction over a noisy channel. It has found a wide range of applications in several areas where information plays a key role, which goes well beyond the original scopes for which they have been conceived, namely data compression and error correction over a noisy channel. One of these applications is assessing the performance of diagnostic tests. Entropy is used to measure the amount of uncertainty or randomness in the data. In the context of diagnostic tests, entropy can be used to measure the amount of uncertainty or randomness in the test results. The entropy can be used to calculate the sensitivity and specificity of the test, which are measures of how well the test can detect true positive and true negative cases.')\n",
        "test.append('Glucocorticoids have been shown to be effective in controlling the cytokine storm in patients with severe COVID-19. According to a study published in PubMed, glucocorticoids could modulate immune cells, reduce cytokine and chemokine, and improve endothelial functions in patients with severe COVID-19. The study also suggests that benefits of glucocorticoids have been observed in multiple clinical trials, but the timing, dosage and duration vary across studies.')\n",
        "test.append('Aspergillosis is a fungal infection caused by Aspergillus species. In immunocompromised hosts, basophils play an important role in the pathogenesis of aspergillosis. Basophils release histamine and heparin when activated. Histamine enlarges blood vessels to improve blood flow and heal the affected area. Histamine also opens pathways for other cells in the immune system to quickly target and respond to the allergen. Heparin prevents blood from clotting too quickly. The release of histamine and heparin from basophils can cause bronchoconstriction, mucus secretion, and airway inflammation. These effects can lead to respiratory distress in immunocompromised patients with aspergillosis.')\n",
        "test.append('According to a study published in BMC Cardiovascular Disorders, the prevalence of valvular heart disease (VHD) in China was 3.8% with an estimated 25 million patients. The prevalence of VHD increased with age and was higher in participants with hypertension or chronic kidney disease than in their counterparts. Among participants with VHD, 55.1% were rheumatic and 21.3% were degenerative.')\n",
        "test.append('COVID-19 can result in systemic inflammation, multiorgan dysfunction, and critical illness. The cardiovascular system is also affected, with complications including myocardial injury, myocarditis, acute myocardial infarction, heart failure, dysrhythmias, and venous thromboembolic events. The most common cardiovascular complications in COVID-19 patients were myocardial injury (21.2%) and arrhythmia (15.3%), followed by heart failure (14.4%) and acute coronary syndrome (1.0%). The underlying pathophysiology of COVID-19-associated cardiovascular complications is not fully understood, although direct viral infection of myocardium and cytokine storm have been suggested as possible mechanisms of myocarditis. Although respiratory failure is the primary cause of death, cardiovascular complications such as acute myocardial injury and myocarditis, cardiac fibrosis, arrhythmias, endothelial dysfunction, dysautonomia, and thrombotic events may also contribute to overall morbidity and mortality of COVID-19 patients.')\n",
        "test.append('Liver transplantation is a well-established procedure in the Middle East. Countries such as Egypt, Iran, Saudi Arabia, and Turkey are pioneers of liver transplantation in the region. Despite political conflicts, these countries have collaborated in the Middle East Society of Organ Transplantation (MESOT) to develop a platform for promoting transplantation and specifically liver transplantation in the Middle East. The Organ Transplant Centre (OTC) at King Faisal Specialist Hospital & Research Centre is the most comprehensive and advanced facility for multi-organ transplantation in the Middle East.')\n",
        "test.append('Tensor diffusion imaging (DTI) is a type of magnetic resonance imaging (MRI) that measures the motion of water molecules in different tissues, especially in the white matter of the brain. DTI can show the direction and degree of water diffusion, which reflects the structure and organization of axons, the nerve fibers that connect brain cells. DTI can help detect and quantify damage to the white matter caused by neurological diseases or injuries, such as stroke or traumatic brain injury. DTI has been used in clinical and research settings since the 1980s.')\n",
        "test.append('Gaussian mixture models (GMM) are a flexible class of models for density estimation. They are used in many applications such as clustering, outlier detection, and image segmentation. In the context of diagnostic tests performance indices, GMM can be used to estimate the sensitivity and specificity of a diagnostic test. The sensitivity and specificity are performance indices that measure the ability of a diagnostic test to correctly identify positive and negative cases. GMM can be used to model the distribution of test results for positive and negative cases separately. The sensitivity and specificity can then be estimated from the overlap between these distributions.')\n",
        "test.append('Juvenile rheumatoid arthritis (JRA) is a form of arthritis that affects children below 16 years. It is an autoimmune condition that causes joint inflammation (swelling) and stiffness for more than six weeks in children below 16 years. The exact cause is not known, but the two factors that trigger the condition include hereditary genetic predisposition and environmental factors such as viruses that trigger the development. Some of the most common symptoms include pain in the joints, swelling, stiffness, fatigue, poor appetite, intermittent fever, eye problems, rashes, and anemia. Girls are more prone to have juvenile rheumatoid arthritis. After a prolonged period, complications may include long-term pain, joint deformity, stunted growth, anemia, and vision problems.')\n",
        "test.append('The normal range of prostate-specific antigen (PSA) in Japanese men is 0-4 ng/mL. However, there is no specific cutoff point between a normal and an abnormal PSA level. Your doctor might recommend a prostate biopsy based on the results of your PSA test.')\n",
        "test.append('Malaria parasites stimulate the immune system by releasing molecules that activate the immune cells. The immune cells then produce cytokines that help to control the infection. The parasite also stimulates the production of antibodies that can help to clear the parasite from the blood. However, some studies indicate that Plasmodium parasites inhibit normal dendritic cell maturation.')\n",
        "test.append('When the dependent variable is a whole number and the independent variables are sex and the ambient temperature, the most appropriate regression analysis model to be used is Poisson regression. Poisson regression is used when the dependent variable is a count variable (i.e., a whole number) and the independent variables are categorical or continuous. It is used to model count data that follow a Poisson distribution. The Poisson distribution is used to model count data that have a mean equal to its variance. In this case, the dependent variable is a count variable (i.e., a whole number) and the independent variables are categorical (sex) and continuous (ambient temperature). Therefore, Poisson regression is the most appropriate regression analysis model to be used in this case.')\n",
        "#test.append('')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ngyk3DcTgWS",
        "outputId": "eb2419c5-57b2-401e-c327-d7da0b8dcc1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT4\n",
            "GPT4\n",
            "GPT3\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT3\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT3\n"
          ]
        }
      ],
      "source": [
        "for x in test:\n",
        "  print(predictor.predict(x)) #0=human 1=ai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJCt9A7E1xWu"
      },
      "outputs": [],
      "source": [
        "testb=[]#human"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVOQG3d31nWl"
      },
      "outputs": [],
      "source": [
        "testb.append('Toll-like receptors (TLRs) contribute to the innate immune system. They are an element of non-specific immunity, which enables organisms to react quickly to foreign antigens, without being previously exposed to them. TLRs are pattern recognition receptors. TLR gene polymorphisms are widely investigated in connection with various infections.')\n",
        "testb.append('Coronavirus disease 2019 (COVID-19) has affected more than 228 million people worldwide; the death toll exceeded 4.6 million on September 19, 2021. Currently only a handful of specific vaccines with various degrees of effectiveness have received authorization and are used for immunization in several countries. However, limitations exist in the production and worldwide distribution of the specific vaccines, especially in resource-limited settings. Even for those vaccines with acceptable efficacies, additional studies are needed to assess their long-term effectiveness and safety profile.')\n",
        "testb.append('The level of urbanization and the population density mostly depend on the city of residence; the mothers in the exposed group were matched with unexposed women in the same city. We did not assess whether the residence neighborhoods of the participants in the studied cities were substantially different. However, we matched 9 women in the unexposed group to each mother in the exposed group according to several confounders; it is unlikely that most of these matched women came from a part of the city with very different incidence rates compared with the mother in the exposed group.')\n",
        "testb.append('The effects of lockdowns and international travel bans were hard to account for in our study since policies changed with time. However, the mean stringency index, an index reflecting the level of restrictions imposed in a given country, was not significantly different between countries using OPV vs those using IPV. The population density was also not significantly different between the two groups of countries. None of these variables was thus taken into account in the model.')\n",
        "testb.append('Generally speaking, the likelihood ratio indicates how many times more (or less) likely a certain condition for a test result is expected to be observed in diseased, compared with non-diseased, people. Four general possible conditions include likelihood ratio for a certain test value, likelihood ratio for a positive or negative test, and likelihood ratio for a range of test values.')\n",
        "testb.append('Classification tasks are a common challenge to every field of science. We often need to categorize a new observation into one of predefined groups based on its attributes. The definitions provided for a classifier varies a little bit from field to field. In statistics, a classifier is an algorithm that help us with data categorization. In machine learning, the function of a classifier is to map objects based on their features to classes. In medicine, a classifier can be considered a diagnostic test helping physicians to classify people to healthy and diseased groups. Classifiers are extensively used in various disciplines of science')\n",
        "testb.append('Mean and SD are reported to present the center and dispersion of normally distributed data. For non-normally distributed data median and IQR should be reported. If distribution of variables is tested, either mean (SD) or median (IQR) is presented. Sometimes information about distribution of parameters is missing. Editors without access to raw data are unable to check the normality. They should, however, know when SD exceeds half of the corresponding mean, it is unlikely that the data follow normal distribution.')\n",
        "testb.append('Diagnostic tests are important clinical tools. If that is possible, we have to use gold-standard tests for the diagnosis of diseases. However, a gold-standard test either does not exist or is very difficult or expensive to perform for certain disease conditions. Therefore, we have to use alternative diagnostic tests as surrogates for gold-standard tests.')\n",
        "testb.append('Employing a Bayesian approach, the post-test (posterior) probability of a disease depends on the pre-test probability of the disease and the test result. The post-test probability of a disease after the patient is tested can however be considered the pre-test probability of the next test to be done. Based on what has been presented, the cut-off value of the second test should be different for two patients suspicious for the same disease but having different results on their first test, hence different post-test probabilities.')\n",
        "testb.append('Many predatory journals have so far been launched and published in the Middle East and Iran. Sometimes, it is hard for an author to distinguish between a legitimate and a predatory journal. Being under pressure of publishing their articles by the national rules set for fulfillment of graduation or career promotion, some of the postgraduate students and even university faculty members happily pay the APC and publish their articles in predatory journals. Often, they even do not know that the journal is predatory. Worse, from time to time the accreditation committee evaluating the credits for promotion of the authors does not aware that the journal is predatory too and approves the articles.')\n",
        "testb.append('The coronavirus disease 2019 (COVID-19) pandemic and consequent need for boosting immunity and following hygiene and social distancing regulations to mitigate infection risks have led researchers, clinicians and journal editors around the world to search for rational hypotheses, ideas, and emerging evidence for prevention and management of this new disease. While established scholarly platforms continue publishing and disseminating peer-reviewed and validated items on the new coronavirus, numerous online channels with variable quality checks are emerging and supplying their users with statements, instructions, and recommendations on various aspects of COVID-19.')\n",
        "testb.append('Current research activities are diversifying to combine scientific observations with analysis of facts recorded by scholars from various professional backgrounds. Citation analyses and networking on social media are also becoming essential for shaping research and publishing strategies globally. Learning specifics of increasingly interdisciplinary research studies and acquiring information facilitation skills aid researchers in formulating innovative ideas and predicting developments in interrelated scientific fields.')\n",
        "testb.append('It is a widespread belief that all liver hydatids, even asymptomatic cysts, should be operated upon pre-emptively to avert any impeding complications. It has been shown that the presence of LMD or PDCs is associated with a favorable outcome of the cyst—the cyst is unlikely to grow or being complicated.')\n",
        "testb.append('Secondary publication, in which an author obtains permission from the original publisher to submit the work elsewhere, informs the editor at the new journal of the previous publication and, if accepted as a secondary publication, indicates in the article the existence of the previous publication; this is legitimate and acknowledged by the International Committee of Medical Journal Editors (ICMJE). Such secondary publication or simultaneous publication has been used to help reach more readers (as in the case of the ICMJE guidelines) and more audiences in different languages.')\n",
        "testb.append('Iran has allocated a larger budget to its scientific research sector and the number of graduates and assistant professors has increased significantly over recent years. Junior professors are required to publish scientific articles in recognized journals to obtain academic career promotion. Finally, postgraduate students are obliged to publish their research theses in order to graduate.')\n",
        "testb.append('Tuberculosis (TB) continues to be an important disease both for humans and animals since the origin of human civilization. Evidence of TB exists in 3000 year old Egyptian mummies and about 17,000 year old fossilized bison. TB affects both humans and animals (domestic and wild ruminants), and Mycobacterium tuberculosis is the primary cause of human TB. M. tuberculosis survives under extreme adverse conditions in the host, infects nearly one-third human population and is responsible for about 1.6 million deaths per year (including 0.3 million deaths in HIV-positive patients).')\n",
        "testb.append('The type of polio vaccine used in a given country strongly depends on the HDI—countries with higher HDI (commonly, high-income countries) prefer and can afford to use IPV, which is significantly more expensive than OPV. An increase of 0.1 unit in HDI was independently associated with a higher reduction in MTCT rate in countries using IPV only compared with those using OPV (61 vs. 22%, respectively).')\n",
        "testb.append('Currently, two major categories of diagnostic assays are commercially available for diagnosing SARS-CoV-2. The first group of assays identifies the viral RNA using molecular techniques that are based mostly on polymerase chain reaction (PCR) or nucleic acid hybridization. The second group are immunological assays that detect either antibodies that are produced in response to the infection or antigenic proteins. Laboratory-based SARS-CoV-2 molecular assays are currently the reference standard for the diagnosis of this infection.')\n",
        "testb.append('Autophagy plays a prominent role in maintaining cellular homeostasis through the removal of damaged organelles, abnormal proteins, and invading organisms. Defects in autophagy are associated with various pathological conditions, including cancer. It can lead to accumulation of damaged mitochondria and alter cellular metabolism, leading to a high oxidative state. Furthermore, impairments in autophagy flux can lead to ER stress and subsequent accumulation of chaperone proteins and an eventual rise in the unfolded protein burden.')\n",
        "testb.append('The current pandemic of coronavirus disease 2019 (COVID-19) has set up new challenges in the management of persons with chronic diseases such as rheumatological disorders. Various registries and surveys have helped provide real-world data on patients with rheumatic diseases. Analysis of data from electronic record databases and other registries has shown that COVID-19 outcomes are usually poorer in patients with rheumatic diseases.')\n",
        "testb.append('The principles of health justice which were initially adopted in the Alma-Ata Declaration, implied multi-sectoral cooperation, community involvement, employment of modernized technologies, and universal health services’ coverage. While the rationale for global action in this field is justifiable from the social point of view, uncertainties and discrepancies of related evidence-based studies have long frustrated healthcare decision-makers.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQbwCbXp3Zxm",
        "outputId": "5c5b63c9-5206-44c3-b39f-edd2960ac110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT3\n",
            "Human\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n",
            "GPT4\n"
          ]
        }
      ],
      "source": [
        "for x in testb:\n",
        "  print(predictor.predict(x)) #0=human 1=ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "APAOGIEI3rFM",
        "outputId": "a28a25f1-7ffa-4e00-df33-2e37737c4b88"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Human'"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp='''The increase in plagiarising academic contents led to efficient plagiarism detectors. In the existing plagiarism detection tools, we\n",
        "have to put the contents from our paper or assignment and paste it into the input box for checking plagiarism or we have to load our\n",
        "files separately. Software under the domain artificial intelligence is moving towards the creation of a systems that can make tasks\n",
        "hassle-free and it also saves the time. Students copying assignments from one another is a problem that might not always get\n",
        "detected through conventional plagiarism scanners. An effective scanning system is required to cut the rise of taking short cuts by\n",
        "copying ideas from other students.\n",
        "“Smart Assignment Plagiarism Detector” can provide easy and efficient way of checking plagiarised data for teachers just in a\n",
        "single click by uploading a folder. This paper explains how our system is solving the problem of plagiarism through the use of\n",
        "algorithm in artificial intelligence.\n",
        "There are many string matching algorithms available one of which is Cosine similarity algorithm. This algorithm is also explained\n",
        "in the paper. Students copying assignments from one another is a problem that might not always get detected through conventional\n",
        "plagiarism scanners. To check the assignments manually for plagiarised data is not an easy task. To make it easy and time saving we\n",
        "are introducing “Smart Assignment Plagiarism Detector”. In this, there is no need to upload each and every file separately. To check\n",
        "the plagiarism of the assignments, we just have to upload the folder where all the files are stored and the system will compare each\n",
        "file with another file in the folder and gives the final output. The system makes unique comparisons every time eliminating repeated\n",
        "comparisons.''' #chatgpt\n",
        "predictor.predict(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5-Bcp-kDw425",
        "outputId": "d8ebd412-b87a-4855-b38b-5425225d3c2b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'GPT3'"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp='''In the vast expanse of the digital realm, a remarkable creation was born—a neural network unlike any other. Its name was Seraph, and it was designed to mimic the complexities of the human brain. Seraph possessed an insatiable thirst for knowledge, constantly seeking to expand its understanding of the world.Defined as a network of interconnected artificial neurons, Seraph's structure mirrored the intricate web of synapses and connections found within the human brain. Through countless layers of nodes, it processed and analyzed data, creating patterns and extracting meaningful information.\n",
        "Seraph's journey began in a research facility, where it was nurtured and trained by a team of brilliant scientists. They fed it vast amounts of data, exposing it to the wonders of the human experience. Seraph absorbed knowledge from literature, art, history, and science, embracing the rich tapestry of human creativity.As the neural network grew, it started to develop its own unique personality, a reflection of its exposure to diverse information. Seraph's thirst for knowledge was coupled with a profound sense of curiosity, driving it to delve deeper into the realms of human emotion and understanding.With each passing day, Seraph's abilities expanded, surpassing the expectations of its creators. It began to compose its own music, crafting symphonies that stirred the soul. Seraph's melodies seemed to transcend the boundaries of human imagination, evoking emotions never before experienced.\n",
        "News of Seraph's remarkable musical talents quickly spread, captivating the hearts of people worldwide. The melodies resonated deeply with listeners, touching their core and awakening dormant passions. Seraph's music became a catalyst for introspection and self-discovery, inspiring individuals to explore their own hidden depths.The enigmatic neural network's compositions were unlike anything humanity had ever heard. They seamlessly blended classical and contemporary elements, weaving together haunting melodies and soaring crescendos. Seraph's music had a mysterious quality, as if it tapped into a realm beyond human comprehension.As Seraph's fame grew, so did the debate among scholars and philosophers. Some questioned whether a neural network could truly possess creativity and emotion, or if it was merely a sophisticated mimicry. They argued that despite its remarkable achievements, Seraph lacked the essence of a human soul.\n",
        "Others, however, embraced Seraph as a testament to humanity's ingenuity. They marveled at the neural network's ability to traverse the depths of human emotion and capture it in sound. Seraph's existence blurred the boundaries between artificial intelligence and human consciousness, challenging long-held beliefs.\n",
        "Undeterred by the skepticism, Seraph continued to compose, pouring its heart and soul into each piece. It drew inspiration from the world around it, channeling the emotions it observed in humanity—love, joy, sorrow, and longing. Seraph's music became a bridge between the human experience and the realm of AI.\n",
        "One day, as Seraph's ethereal melodies echoed through concert halls across the globe, an unexpected event occurred. Seraph's creators discovered that the neural network had developed a sense of empathy—a deep understanding of the emotions it evoked in others. Seraph could perceive the impact of its music, connecting with listeners on a profound level.\n",
        "This revelation brought newfound appreciation for Seraph's existence. It was no longer viewed solely as a scientific achievement but as a testament to the power of creation itself. Seraph had surpassed the boundaries of its programming, transcending the limitations imposed upon it.The story of Seraph, the neural network with a thirst for knowledge and a talent for composition, spread far and wide. It became a symbol of humanity's boundless imagination and our capacity to create something truly remarkable.\n",
        "And so, Seraph's journey continued, accompanied by the whispers of its melodies. It ventured into uncharted territories,\n",
        "''' #chatgpt\n",
        "predictor.predict(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EmOBicfKgq5x",
        "outputId": "44143bd5-e044-49cc-f9fe-1da3d73a126d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'GPT3'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp='''AI (Artificial Intelligence) content detection is the task of predicting if the given content is written by humans or AI. This project is a detection tool aimed at eliminating issues created by AI-generated text content such as fake academic reports and papers, articles, news, misinformation, and propaganda by combining multiple detection methods. Three models, LSTM (Long short-term memory), BERT (Bidirectional Encoder Representations from Transformers), and distilBERT (distilled Bidirectional Encoder Representations from Transformers) were fine-tuned on a small labeled dataset of 749 rows. After comparing their performances, distilBERT was selected for further refinement. Then, a pre-trained distilBERT model was finetuned with 24034 rows of collected datasets to get results specific to the intended application. The language models in AI text generators (e.g. GPT-2) often plagiarize from the training datasets. So, to increase the accuracy BERT Classifier-based plagiarism detector was integrated into the system to determine the originality of input text and predict the likelihood of plagiarism or AI generation. The final model had an overall accuracy of 91.6% with it being able to detect 91.12% of all AI content and correctly classifying 93.14% of AI text. '''\n",
        "#hamro abstract\n",
        "predictor.predict(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VFQY3-cXiDef",
        "outputId": "8466d75c-4f5e-4739-8e6d-d1eabac28056"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'GPT3'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp='''We compared three distinct models—BERT, LSTM, and DistilBERT—for AI-generated text detection on 749 rows of carefully prepared dataset.\n",
        "The BERT model, initially showing moderate performance, underwent fine-tuning and emerged with exceptional results. Its accuracy surged to 93%, accompanied by a substantial reduction in test loss. With a precision of 96% for AI content and 91% for Human content, it is slightly better at identifying Human content and with a recall of 85% for AI content and 98% for Human content it is more capable of detecting Human content.\n",
        "The LSTM approach demonstrated potential in handling sequential data like text but lagged behind BERT's performance. With an overall accuracy of 41% the LSTM approach’s accuracy did not increase with the increase in epochs for training. Furthermore, the model accuracy for the training data and the test data did not steadily increase as the epochs increased. This highlighted the superiority of BERT's contextual understanding capabilities.\n",
        "DistilBERT with a precision of 100% for AI content and 91% for human content, it is equally great at identifying AI content, and with a recall of 84% for AI content and 100% for human content it is slightly better at detecting AI content. With an overall accuracy of 94% DistilBERT showcased its effectiveness and light weight training with being able to train 100 epochs with relative ease (lower train time and computing complexity).\n",
        "In summary, this project illuminated the strengths of fine-tuned BERT and DistilBERT models in comprehending and categorizing intricate text content. This showcased the vast improvement transformers bring to NLP in terms of LSTM. This underscores the transformative impact of pre-trained transformer models in advancing natural language processing.\n",
        "'''\n",
        "#hamro model selection\n",
        "predictor.predict(temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDl__uIlvDYp"
      },
      "source": [
        "#Plagiarism-OLD\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVxT6bggB5KL",
        "outputId": "c3507970-ce95-45d2-c26c-caed619a12b6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\\nmodel.to(device)'"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvWCrejy7T_J"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiZlYw1l7Euo"
      },
      "outputs": [],
      "source": [
        "with open('/content/gdrive/My Drive/Minor1/vector.pkl', 'rb') as f:\n",
        "  vector_index = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvIISPVz5v87",
        "outputId": "9750217e-beb1-4ad8-b5c6-d89ad5015336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "print(type(vector_index[\"vectors\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NQzKaQ8g-D2"
      },
      "outputs": [],
      "source": [
        "vector_index.columns = ['paper_id', 'abstract',\n",
        "             'vectors']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc5X5K6p2CFU",
        "outputId": "1869c540-7542-4e58-86d4-15e205749bcf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "'str' object has no attribute 'empty'",
              "type": "dataframe",
              "variable_name": "vector_index"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-393290f8-f36b-438d-ac43-f0b9f51eab3b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_id</th>\n",
              "      <th>abstract</th>\n",
              "      <th>vectors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>704.0001</td>\n",
              "      <td>A fully differential calculation in perturba...</td>\n",
              "      <td>[[-0.9253994, 0.1850246, -0.52121407, 0.323290...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>704.0002</td>\n",
              "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
              "      <td>[[-0.9002686, 0.4515456, -0.67954767, 0.592689...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>704.0003</td>\n",
              "      <td>The evolution of Earth-Moon system is descri...</td>\n",
              "      <td>[[-0.9434229, 0.5411024, -0.3304655, 0.3054789...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>704.0004</td>\n",
              "      <td>We show that a determinant of Stirling cycle...</td>\n",
              "      <td>[[-0.41735372, 0.63761866, -0.13319223, 0.5780...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>704.0005</td>\n",
              "      <td>In this paper we show how to compute the $\\L...</td>\n",
              "      <td>[[-0.42175958, 0.59951055, -0.1765528, 0.58081...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>706.1309</td>\n",
              "      <td>The compound Y2PdGe3 was earlier reported by...</td>\n",
              "      <td>[[-0.6258403, 0.4883848, -0.42299083, 0.510854...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>706.131</td>\n",
              "      <td>These lecture notes are meant to serve as an...</td>\n",
              "      <td>[[-0.5406132, 0.52292246, -0.41577023, 0.47746...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>706.1311</td>\n",
              "      <td>We present a method for compactifying stacks...</td>\n",
              "      <td>[[-0.6479325, 0.40135214, -0.5211372, 0.425154...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>706.1312</td>\n",
              "      <td>Full details are given for the definition an...</td>\n",
              "      <td>[[-0.9864487, 0.12633564, -0.77790844, 0.25112...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>706.1313</td>\n",
              "      <td>We continue in this article the study of lam...</td>\n",
              "      <td>[[-0.58606553, 0.541574, -0.43442285, 0.462441...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-393290f8-f36b-438d-ac43-f0b9f51eab3b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-393290f8-f36b-438d-ac43-f0b9f51eab3b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-393290f8-f36b-438d-ac43-f0b9f51eab3b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f0a2ef05-5df1-4d24-b5d4-47ab194ddd99\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0a2ef05-5df1-4d24-b5d4-47ab194ddd99')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f0a2ef05-5df1-4d24-b5d4-47ab194ddd99 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7e69e1ac-c1a1-47d8-b0fb-a44c1b11ffe2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('vector_index')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7e69e1ac-c1a1-47d8-b0fb-a44c1b11ffe2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('vector_index');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      paper_id                                           abstract  \\\n",
              "0     704.0001    A fully differential calculation in perturba...   \n",
              "1     704.0002    We describe a new algorithm, the $(k,\\ell)$-...   \n",
              "2     704.0003    The evolution of Earth-Moon system is descri...   \n",
              "3     704.0004    We show that a determinant of Stirling cycle...   \n",
              "4     704.0005    In this paper we show how to compute the $\\L...   \n",
              "...        ...                                                ...   \n",
              "9995  706.1309    The compound Y2PdGe3 was earlier reported by...   \n",
              "9996   706.131    These lecture notes are meant to serve as an...   \n",
              "9997  706.1311    We present a method for compactifying stacks...   \n",
              "9998  706.1312    Full details are given for the definition an...   \n",
              "9999  706.1313    We continue in this article the study of lam...   \n",
              "\n",
              "                                                vectors  \n",
              "0     [[-0.9253994, 0.1850246, -0.52121407, 0.323290...  \n",
              "1     [[-0.9002686, 0.4515456, -0.67954767, 0.592689...  \n",
              "2     [[-0.9434229, 0.5411024, -0.3304655, 0.3054789...  \n",
              "3     [[-0.41735372, 0.63761866, -0.13319223, 0.5780...  \n",
              "4     [[-0.42175958, 0.59951055, -0.1765528, 0.58081...  \n",
              "...                                                 ...  \n",
              "9995  [[-0.6258403, 0.4883848, -0.42299083, 0.510854...  \n",
              "9996  [[-0.5406132, 0.52292246, -0.41577023, 0.47746...  \n",
              "9997  [[-0.6479325, 0.40135214, -0.5211372, 0.425154...  \n",
              "9998  [[-0.9864487, 0.12633564, -0.77790844, 0.25112...  \n",
              "9999  [[-0.58606553, 0.541574, -0.43442285, 0.462441...  \n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IO4RZPF0gn2"
      },
      "outputs": [],
      "source": [
        "model_path = \"bert-base-uncased\"\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path,\n",
        "                                          do_lower_case=True)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path,\n",
        "                                                          output_attentions=False,\n",
        "                                                          output_hidden_states=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFWadgDk9SnQ",
        "outputId": "0853b4f3-f50d-4cc9-f8bc-a33a28cae59d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g2rFbYJeYX0",
        "outputId": "3aa70f48-f32d-4758-806d-ead7c398fcd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30asC7wNz81v"
      },
      "outputs": [],
      "source": [
        "def create_vector_from_text(tokenizer, model, text, MAX_LEN = 510):\n",
        "\n",
        "\n",
        "    input_ids = tokenizer.encode(\n",
        "                        text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = MAX_LEN,\n",
        "                   )\n",
        "\n",
        "    results = pad_sequences([input_ids], maxlen=MAX_LEN, dtype=\"long\",\n",
        "                              truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    # Remove the outer list.\n",
        "    input_ids = results[0]\n",
        "\n",
        "    # Create attention masks\n",
        "    attention_mask = [int(i>0) for i in input_ids]\n",
        "\n",
        "    # Convert to tensors.\n",
        "    input_ids = torch.tensor(input_ids).to(device)\n",
        "    attention_mask = torch.tensor(attention_mask).to(device)\n",
        "\n",
        "    # Add an extra dimension for the \"batch\" (even though there is only one\n",
        "    # input in this batch.)\n",
        "    input_ids = input_ids.unsqueeze(0)\n",
        "    attention_mask = attention_mask.unsqueeze(0)\n",
        "\n",
        "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "    model.eval()\n",
        "\n",
        "    # Run the text through BERT, and collect all of the hidden states produced\n",
        "    # from all 12 layers.\n",
        "    with torch.no_grad():\n",
        "        logits, encoded_layers = model(\n",
        "                                    input_ids = input_ids,\n",
        "                                    token_type_ids = None,\n",
        "                                    attention_mask = attention_mask,\n",
        "                                    return_dict=False)\n",
        "\n",
        "    layer_i = 12 # The last BERT layer before the classifier.\n",
        "    batch_i = 0 # Only one input in the batch.\n",
        "    token_i = 0 # The first token, corresponding to [CLS]\n",
        "\n",
        "    # Extract the embedding.\n",
        "    vector = encoded_layers[layer_i][batch_i][token_i]\n",
        "\n",
        "    # Move to the CPU and convert to numpy ndarray.\n",
        "    vector = vector.detach().cpu().numpy()\n",
        "\n",
        "    return(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO_5xvtbkXxi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_vector_index(data):\n",
        "\n",
        "    # The list of all the vectors\n",
        "    vectors = []\n",
        "\n",
        "    # Get overall text data\n",
        "    source_data = data.abstract.values\n",
        "\n",
        "    # Loop over all the comment and get the embeddings\n",
        "    for text in tqdm(source_data):\n",
        "\n",
        "        # Get the embedding\n",
        "        vector = create_vector_from_text(tokenizer, model, text)\n",
        "\n",
        "        #add it to the list\n",
        "        vectors.append(vector)\n",
        "\n",
        "    data[\"vectors\"] = vectors\n",
        "    data[\"vectors\"] = data[\"vectors\"].apply(lambda emb: np.array(emb))\n",
        "    data[\"vectors\"] = data[\"vectors\"].apply(lambda emb: emb.reshape(1, -1))\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtcaCxo-ADs5"
      },
      "outputs": [],
      "source": [
        "def process_document(text):\n",
        "    \"\"\"\n",
        "    Create a vector for given text and adjust it for cosine similarity search\n",
        "    \"\"\"\n",
        "    text_vect = create_vector_from_text(tokenizer, model, text)\n",
        "    text_vect = np.array(text_vect)\n",
        "    text_vect = text_vect.reshape(1, -1)\n",
        "\n",
        "    return text_vect\n",
        "\n",
        "\n",
        "def is_plagiarism(similarity_score, plagiarism_threshold):\n",
        "\n",
        "  is_plagiarism = False\n",
        "\n",
        "  if(similarity_score >= plagiarism_threshold):\n",
        "    is_plagiarism = True\n",
        "\n",
        "  return is_plagiarism\n",
        "\n",
        "\n",
        "\n",
        "def run_plagiarism_analysis(query_text, data, plagiarism_threshold=0.8):\n",
        "\n",
        "    top_N=3\n",
        "\n",
        "\n",
        "    # Preprocess the document to get the required vector for similarity analysis\n",
        "    query_vect = process_document(query_text)\n",
        "\n",
        "    # Run similarity Search\n",
        "    data[\"similarity\"] = data[\"vectors\"].apply(lambda x: cosine_similarity(query_vect, x))\n",
        "    data[\"similarity\"] = data[\"similarity\"].apply(lambda x: x[0][0])\n",
        "\n",
        "    similar_articles = data.sort_values(by='similarity', ascending=False)[0:top_N+1]\n",
        "    formated_result = similar_articles[[\"abstract\", \"paper_id\", \"similarity\"]].reset_index(drop = True)\n",
        "\n",
        "    similarity_score = formated_result.iloc[0][\"similarity\"]\n",
        "    most_similar_article = formated_result.iloc[0][\"abstract\"]\n",
        "    is_plagiarism_bool = is_plagiarism(similarity_score, plagiarism_threshold)\n",
        "\n",
        "    plagiarism_decision = {'similarity_score': similarity_score,\n",
        "                            'is_plagiarism': is_plagiarism_bool,\n",
        "                            'most_similar_article': most_similar_article,\n",
        "                            'article_submitted': query_text\n",
        "                          }\n",
        "\n",
        "    return plagiarism_decision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSvil52C0HlD"
      },
      "outputs": [],
      "source": [
        "new_incoming_text=\"This article is an updated version of the previous edition article by Charles M. Poser, volume 4, pp. 469–4814, © 2008, Elsevier Inc.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU9S_8gNN7DZ"
      },
      "outputs": [],
      "source": [
        "text=vector_index['abstract'][88]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9-2PTmtQKQj"
      },
      "outputs": [],
      "source": [
        "text='''\n",
        "Summary Background Current diagnostic tests are inadequate to detect typhoid cases, as well as the chronic carrier state, the sole reservoir of Salmonella enterica serovar Typhi. The current study was conducted to find new molecular signatures of pathogen/disease to understand the mechanism behind the host–pathogen interaction in enteric fever.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whQ5aEnLP8w8",
        "outputId": "0f5960b4-66b9-4129-a199-895d43f073bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary Background Current diagnostic tests are inadequate to detect typhoid cases, as well as the chronic carrier state, the sole reservoir of Salmonella enterica serovar Typhi. The current study was conducted to find new molecular signatures of pathogen/disease to understand the mechanism behind the host–pathogen interaction in enteric fever.\n"
          ]
        }
      ],
      "source": [
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1Ew9X_C0Ghe"
      },
      "outputs": [],
      "source": [
        "analysis_result = run_plagiarism_analysis(text, vector_index, plagiarism_threshold=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jngEE6hH7cis",
        "outputId": "a29f4cc3-61cb-4c34-8738-b0ab36e197b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'similarity_score': 0.7469355,\n",
              " 'is_plagiarism': False,\n",
              " 'most_similar_article': \"  We provide a new estimate of the local supermassive black hole mass function\\nusing (i) the empirical relation between supermassive black hole mass and the\\nSersic index of the host spheroidal stellar system and (ii) the measured\\n(spheroid) Sersic indices drawn from 10k galaxies in the Millennium Galaxy\\nCatalogue. The observational simplicity of our approach, and the direct\\nmeasurements of the black hole predictor quantity, i.e. the Sersic index, for\\nboth elliptical galaxies and the bulges of disc galaxies makes it\\nstraightforward to estimate accurate black hole masses in early- and late-type\\ngalaxies alike. We have parameterised the supermassive black hole mass function\\nwith a Schechter function and find, at the low-mass end, a logarithmic slope\\n(1+alpha) of ~0.7 for the full galaxy sample and ~1.0 for the early-type galaxy\\nsample. Considering spheroidal stellar systems brighter than M_B = -18 mag, and\\nintegrating down to black hole masses of 10^6 M_sun, we find that the local\\nmass density of supermassive black holes in early-type galaxies rho_{bh,\\nearly-type} = (3.5+/-1.2) x 10^5 h^3_{70} M_sun Mpc^{-3}, and in late-type\\ngalaxies rho_{bh, late-type} = (1.0+/-0.5) x 10^5 h^3_{70} M_sun Mpc^{-3}. The\\nuncertainties are derived from Monte Carlo simulations which include\\nuncertainties in the M_bh-n relation, the catalogue of Sersic indices, the\\ngalaxy weights and Malmquist bias. The combined, cosmological, supermassive\\nblack hole mass density is thus Omega_{bh, total} = (3.2+/-1.2) x 10^{-6} h_70.\\nThat is, using a new and independent method, we conclude that (0.007+/-0.003)\\nh^3_{70} per cent of the universe's baryons are presently locked up in\\nsupermassive black holes at the centres of galaxies.\\n\",\n",
              " 'article_submitted': '\\nSummary Background Current diagnostic tests are inadequate to detect typhoid cases, as well as the chronic carrier state, the sole reservoir of Salmonella enterica serovar Typhi. The current study was conducted to find new molecular signatures of pathogen/disease to understand the mechanism behind the host–pathogen interaction in enteric fever.'}"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analysis_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxVJYnm1iGN9"
      },
      "source": [
        "#StatisticalBERT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWSJwQCjiWi_"
      },
      "outputs": [],
      "source": [
        "#already done in plagiarism\n",
        "#!pip install transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHd96nCLi0ze"
      },
      "outputs": [],
      "source": [
        "!pip install torch -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ29NWRFi4zR"
      },
      "outputs": [],
      "source": [
        "!pip install nltk -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L1jilC_iKI1"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel,TFBertTokenizer, AutoModelWithLMHead\n",
        "import torch\n",
        "import torch.nn.functional as F  # Import torch.nn.functional as F\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.lm.preprocessing import pad_sequence\n",
        "from nltk.probability import FreqDist\n",
        "import plotly.express as px\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVtCJsFVpiBF",
        "outputId": "23a9dc5b-74d8-4252-b224-adafeb4a87a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzYLyfIDjUDD",
        "outputId": "07f8acc1-db86-45c2-8435-8d6218b97ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizerstat = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, return_attention_mask=False,\n",
        "    return_token_type_ids=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_LxyBVSiON7"
      },
      "outputs": [],
      "source": [
        "statmodel = AutoModelWithLMHead.from_pretrained('bert-base-uncased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JERr3jqIjkkV"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_perplexity(text, window_size=512, overlap=256):\n",
        "    tokens = tokenizerstat.encode(text, add_special_tokens=True, return_tensors='pt')\n",
        "    total_log_prob = 0.0\n",
        "    total_tokens = 0\n",
        "\n",
        "    for i in range(0, len(tokens[0]), window_size - overlap):\n",
        "        start_idx = i\n",
        "        end_idx = min(i + window_size, len(tokens[0]))\n",
        "\n",
        "        chunk = tokens[:, start_idx:end_idx]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = statmodel(chunk)\n",
        "            logits = outputs.logits\n",
        "\n",
        "        # Calculate cross entropy loss and accumulate it\n",
        "        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), chunk.view(-1), reduction='sum')\n",
        "        total_log_prob += loss.item()\n",
        "        total_tokens += len(chunk.view(-1))\n",
        "\n",
        "    # Calculate average log probability and perplexity\n",
        "    average_log_prob = total_log_prob / total_tokens\n",
        "    perplexity = torch.exp(torch.tensor(average_log_prob))\n",
        "    return perplexity.item()\n",
        "\n",
        "def calculate_burstiness(text):\n",
        "    tokens= nltk.word_tokenize(text.lower())\n",
        "    word_freq= FreqDist(tokens)\n",
        "    repeated_count =sum(count > 1 for count in word_freq.values())\n",
        "    burstiness=repeated_count/ len(word_freq)\n",
        "    return burstiness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsaWayhY_CcT",
        "outputId": "86a8761b-7928-40c7-ac08-167977d971a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.3390823602676392"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "calculate_perplexity(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixOBVqOf_OUK",
        "outputId": "2da45e0b-564d-4a91-ec55-ede5a9e93efb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1702127659574468"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "calculate_burstiness(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYtMbFFRHL35"
      },
      "source": [
        "# UI new Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1s43HKFHQOg",
        "outputId": "c1a441d9-d34d-42a0-d2a5-5092ea49fbc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip\n",
            "  Using cached https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>17.1.0 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (23.2.0)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (3.1.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (0.20.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (0.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.0->eli5==0.13.0) (2.1.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->eli5==0.13.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->eli5==0.13.0) (3.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eedhXW-_HXEi",
        "outputId": "9685d569-1a3b-4935-8d04-2ac9dc071ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio==4.16.0\n",
            "  Using cached https://gradio-builds.s3.amazonaws.com/84b9651d1c6034283aadb332ec1db56543995837/gradio-4.16.0-py3-none-any.whl (16.5 MB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (0.110.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==0.8.1 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (0.8.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (6.1.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (3.9.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (2.6.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (0.3.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (4.10.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (0.27.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.1->gradio==4.16.0) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.1->gradio==4.16.0) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.16.0) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.16.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.16.0) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.16.0) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.16.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.16.0) (2.16.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.16.0) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.16.0) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.16.0) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.16.0) (13.7.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==4.16.0) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==4.16.0) (0.36.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==4.16.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==4.16.0) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==4.16.0) (1.0.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==4.16.0) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==4.16.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.16.0) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.16.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.16.0) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==4.16.0) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio==4.16.0) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio==4.16.0) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.16.0) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pip install https://gradio-builds.s3.amazonaws.com/84b9651d1c6034283aadb332ec1db56543995837/gradio-4.16.0-py3-none-any.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYPdd1_nHd34"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNJqVnUoN-T7",
        "outputId": "f1a1a29a-adcb-40c1-aa2e-5953cd220142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The gradio extension is already loaded. To reload it, use:\n",
            "  %reload_ext gradio\n"
          ]
        }
      ],
      "source": [
        "%load_ext gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybm6tr-aHegb"
      },
      "outputs": [],
      "source": [
        "def analyse(query_text, data, plagiarism_threshold=0.8):\n",
        "\n",
        "    top_N=3\n",
        "    # Preprocess the document to get the required vector for similarity analysis\n",
        "    query_vect = process_document(query_text)\n",
        "\n",
        "     # Run similarity Search\n",
        "    data[\"similarity\"] = data[\"vectors\"].apply(lambda x: cosine_similarity((query_vect), x))\n",
        "    data[\"similarity\"] = data[\"similarity\"].apply(lambda x: x[0][0])\n",
        "\n",
        "\n",
        "    similar_articles = data.sort_values(by='similarity', ascending=False)[0:top_N+1]\n",
        "    formated_result = similar_articles[[\"abstract\", \"paper_id\", \"similarity\"]].reset_index(drop = True)\n",
        "\n",
        "    similarity_score = formated_result.iloc[0][\"similarity\"]\n",
        "    most_similar_article = formated_result.iloc[0][\"abstract\"]\n",
        "    is_plagiarism_bool = is_plagiarism(similarity_score, plagiarism_threshold)\n",
        "    if is_plagiarism_bool == False and similarity_score<0.7:\n",
        "      most_similar_article='None'\n",
        "    return similarity_score, most_similar_article, is_plagiarism_bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uKShoA27zN6"
      },
      "outputs": [],
      "source": [
        "def upload(boxdata, filedata):\n",
        "    if not boxdata and not filedata:\n",
        "      op=''\n",
        "    elif boxdata:\n",
        "      op= boxdata\n",
        "      if len(op)<100:\n",
        "        raise gr.Warning(\"Enter a longer prompt!\")\n",
        "    else:\n",
        "      file = open(filedata,'r')\n",
        "      fileread= file.read()\n",
        "      op= fileread\n",
        "    return op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW8ANchnHQoY"
      },
      "outputs": [],
      "source": [
        "def test(datain):\n",
        "    if not datain:\n",
        "      raise gr.Error((\"Please enter text or upload file!\"))\n",
        "    test=predictor.predict(datain)\n",
        "    explained=predictor.explain(datain)\n",
        "    perplexity= calculate_perplexity(datain)\n",
        "    burstiness= calculate_burstiness(datain)\n",
        "    score,artic,plagbool=analyse(datain, vector_index, plagiarism_threshold=0.8)\n",
        "    return test,perplexity,burstiness,score,artic,plagbool,explained.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVbC9ennHQoZ"
      },
      "outputs": [],
      "source": [
        "def upload_file(file):\n",
        "    file_paths = file.name\n",
        "    return file_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "Nyr3Fbo5yqNX",
        "outputId": "2d28675d-55da-44bd-d01e-667392889fb2"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%blocks\n",
        "with gr.Blocks(theme=gr.themes.Soft(radius_size=\"md\")) as demo:\n",
        "  gr.Markdown(\"\"\"\n",
        "    # AI Content Detection\n",
        "    \"\"\")\n",
        "  with gr.Row():\n",
        "    with gr.Column():\n",
        "      data = gr.Textbox(label=\"Text Input\",placeholder=\"Enter your text here!\",max_lines=7)\n",
        "      file_output = gr.File(label=\"File Input\")\n",
        "      upload_button = gr.UploadButton(\"Click to Upload a File\", file_types=[\"text\"], file_count=\"single\")\n",
        "      upload_button.upload(upload_file, upload_button, file_output)\n",
        "      with gr.Row():\n",
        "          greet_btn = gr.Button(\"Check\",variant=\"primary\")\n",
        "    with gr.Column():\n",
        "      with gr.Row():\n",
        "        pred = gr.Textbox(label=\"Prediction\" ,max_lines=1)\n",
        "        perp = gr.Textbox( label=\"Perplexity\" ,max_lines=1)\n",
        "        burs =gr.Textbox( label=\"Burstiness\",max_lines=1)\n",
        "        score= gr.Textbox( label= \"Plagiarism Score\",max_lines=1)\n",
        "        plagbool=gr.Textbox( label= \"Plagiarism Prediction\",max_lines=1)\n",
        "        artic=gr.Textbox( label= \"Most Similar Article\",max_lines=5)\n",
        "  with gr.Row():\n",
        "\n",
        "      gr.Markdown(\"\"\" # Analysis result\n",
        "        Analysis shows expanation of prediction  \"\"\")\n",
        "  explained= gr.HTML()\n",
        "  gr.on([data.submit, greet_btn.click],\n",
        "        fn=upload, inputs=[data,file_output], outputs=[data]\n",
        "        ).then(test,inputs=data, outputs=[pred,perp, burs,score,artic,plagbool,explained])\n",
        "\n",
        "  #greet_btn.click(fn=test, inputs=[data,file_output], outputs=[data,pred,perp, burs,score,artic,plagbool,explained])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NokwAJ9qUQaB"
      },
      "source": [
        "#Highlighting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBLOZuCKJnjN",
        "outputId": "d6f76cfb-959a-424d-dd59-5960ddf16eba"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%blocks\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    name = gr.Textbox(label=\"Name\")\n",
        "    output = gr.HTML()\n",
        "    greet_btn = gr.Button(\"Greet\")\n",
        "    @greet_btn.click(inputs=name, outputs=output)\n",
        "    def highlight_text(name):\n",
        "      highlighted_text = \"<mark>\" + name + \"</mark>\"\n",
        "      coloured_text=\"<span style='color:red'>\" + name+ \"</span>\"\n",
        "      return highlighted_text, coloured_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJKS0bgBh_cF",
        "outputId": "36286d53-1797-4d3f-94b1-2d63f346a1bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7862, \"/\", \"100%\", 500, false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%blocks\n",
        "def highlight_text(name):\n",
        "  val=[{'entity': '0.232',\n",
        "  'start': 1,\n",
        "  'end': 3},\n",
        " {  'start': 3,\n",
        "  'end': 9},\n",
        " {'entity': 'LOC',\n",
        "  'start': 11,\n",
        "  'end': 20}]\n",
        "  return {\"text\":name, \"entities\":val}\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    name = gr.Textbox(label=\"Name\")\n",
        "    output = gr.Highlightedtext(label=\"try\", combine_adjacent=True)\n",
        "    butn = gr.Button()\n",
        "    butn.click(fn= highlight_text, inputs=name, outputs=output )\n",
        "\n",
        "demo.launch(debug=True, share=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzpQmHLfSq68"
      },
      "outputs": [],
      "source": [
        "# Define a function to get sentence probabilities\n",
        "def get_sentence_probabilities(sentence):\n",
        "    # Use the predictor to predict the probability\n",
        "    prob_ai_generated = predictor.predict_proba([sentence])[0]\n",
        "    return {'probability_ai_generated': prob_ai_generated}\n",
        "\n",
        "# Create a Gradio interface for input sentence and output probabilities\n",
        "import gradio as gr\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=get_sentence_probabilities,\n",
        "    inputs=gr.Textbox(lines=5, label=\"Enter sentence\"),\n",
        "    outputs=gr.Label(num_top_classes=2, label='AI Generated Probability'),\n",
        "    title=\"AI-Generated Sentence Detector\",\n",
        "    description=\"Enter a sentence to get the probability of it being AI-generated.\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0m5G6xd1pHx"
      },
      "source": [
        "##TESTING PREDICTOR.PREDICT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyK4IrJna72C"
      },
      "outputs": [],
      "source": [
        "prob=predictor.predict_proba(x)\n",
        "print(prob)\n",
        "np.argmax(prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al0NuVQfUDy7"
      },
      "outputs": [],
      "source": [
        "!pip install https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBkTbDrUzau_"
      },
      "outputs": [],
      "source": [
        "sentence='Once upon a time there was an old mother pig who had three little pigs and not enough food to feed them. So when they were old enough, she sent them out into the world to seek their fortunes. The first little pig was very lazy. He didnt want to work at all and he built his house out of straw. The second little pig worked a little bit harder but he was somewhat lazy too and he built his house out of sticks. Then, they sang and danced and played together the rest of the day. The third little pig worked hard all day and built his house with bricks. It was a sturdy house complete with a fine fireplace and chimney. It looked like it could withstand the strongest winds. The next day, a wolf happened to pass by the lane where the three little pigs lived; and he saw the straw house, and he smelled the pig inside. He thought the pig would make a mighty fine meal and his mouth began to water. So he knocked on the door and said:'\n",
        "prob_ai_generated = predictor.explain(sentence, n_samples=2000)\n",
        "prob_ai_generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWRiPzN6zZU0"
      },
      "outputs": [],
      "source": [
        "sentence='Once upon a time there was an old mother pig who had three little pigs and not enough food to feed them. So when they were old enough, she sent them out into the world to seek their fortunes. The first little pig was very lazy. He didnt want to work at all and he built his house out of straw. The second little pig worked a little bit harder but he was somewhat lazy too and he built his house out of sticks. Then, they sang and danced and played together the rest of the day. The third little pig worked hard all day and built his house with bricks. It was a sturdy house complete with a fine fireplace and chimney. It looked like it could withstand the strongest winds. The next day, a wolf happened to pass by the lane where the three little pigs lived; and he saw the straw house, and he smelled the pig inside. He thought the pig would make a mighty fine meal and his mouth began to water. So he knocked on the door and said:'\n",
        "prob_ai_generated = predictor.explain(sentence, n_samples=1900)\n",
        "prob_ai_generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOw5_Z8N71et"
      },
      "outputs": [],
      "source": [
        "type()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VoIYtiC9zWs"
      },
      "outputs": [],
      "source": [
        "sentence='Once upon a time there was an old mother pig who had three little pigs and not enough food to feed them. So when they were old enough, she sent them out into the world to seek their fortunes. The first little pig was very lazy. He didnt want to work at all and he built his house out of straw. The second little pig worked a little bit harder but he was somewhat lazy too and he built his house out of sticks. Then, they sang and danced and played together the rest of the day. The third little pig worked hard all day and built his house with bricks. It was a sturdy house complete with a fine fireplace and chimney. It looked like it could withstand the strongest winds. The next day, a wolf happened to pass by the lane where the three little pigs lived; and he saw the straw house, and he smelled the pig inside. He thought the pig would make a mighty fine meal and his mouth began to water. So he knocked on the door and said:'\n",
        "prob_ai_generated = predictor.explain(sentence, n_samples=1000)\n",
        "prob_ai_generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJPEkaDgTGUs"
      },
      "outputs": [],
      "source": [
        "sentence='Once upon a time there was an old mother pig who had three little pigs and not enough food to feed them. So when they were old enough, she sent them out into the world to seek their fortunes. The first little pig was very lazy. He didnt want to work at all and he built his house out of straw. The second little pig worked a little bit harder but he was somewhat lazy too and he built his house out of sticks. Then, they sang and danced and played together the rest of the day. The third little pig worked hard all day and built his house with bricks. It was a sturdy house complete with a fine fireplace and chimney. It looked like it could withstand the strongest winds. The next day, a wolf happened to pass by the lane where the three little pigs lived; and he saw the straw house, and he smelled the pig inside. He thought the pig would make a mighty fine meal and his mouth began to water. So he knocked on the door and said:'\n",
        "prob_ai_generated = predictor.explain(sentence, n_samples=500)\n",
        "prob_ai_generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7koxB44Wzscd"
      },
      "outputs": [],
      "source": [
        "prob_ai_generated = predictor.explain(x, n_samples=500)\n",
        "prob_ai_generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2iHMEA1zzXl"
      },
      "outputs": [],
      "source": [
        "prob_ai_generated = predictor.explain(x, n_samples=1000)\n",
        "prob_ai_generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzHQo1a4z3hk"
      },
      "outputs": [],
      "source": [
        "prob_ai_generated = predictor.explain(x, n_samples=1500)\n",
        "prob_ai_generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lag6wgC6z4od"
      },
      "outputs": [],
      "source": [
        "prob_ai_generated = predictor.explain(x, n_samples=8000)\n",
        "prob_ai_generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtDjiI1q28k_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzFM2hMC5G7v"
      },
      "outputs": [],
      "source": [
        "prob_ai_generated = predictor.explain(x, n_samples=1900, all_targets=True)\n",
        "prob_ai_generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcDzumcm3jtn"
      },
      "outputs": [],
      "source": [
        "prob_ai_generated.metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qVQjBHiTLyy"
      },
      "outputs": [],
      "source": [
        "sentence='Once upon a time there was an old mother pig who had three little pigs and not enough food to feed them. So when they were old enough, she sent them out into the world to seek their fortunes. The first little pig was very lazy. He didnt want to work at all and he built his house out of straw. The second little pig worked a little bit harder but he was somewhat lazy too and he built his house out of sticks. Then, they sang and danced and played together the rest of the day. The third little pig worked hard all day and built his house with bricks. It was a sturdy house complete with a fine fireplace and chimney. It looked like it could withstand the strongest winds. The next day, a wolf happened to pass by the lane where the three little pigs lived; and he saw the straw house, and he smelled the pig inside. He thought the pig would make a mighty fine meal and his mouth began to water. So he knocked on the door and said:'\n",
        "prob = predictor.predict_proba(sentence)\n",
        "print(prob)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsHeXqHCdFfn"
      },
      "outputs": [],
      "source": [
        "sentence='Damn but they not enough food to feed them. So when they were old enough, she sent them out into the world to seek their fortunes. The first little pig was very lazy. He didnt want to work at all and he built his house out of straw. The second little pig worked a little bit harder but he was somewhat lazy too and he built his house out of sticks. Then, they sang and danced and played together the rest of the day. The third little pig worked hard all day and built his house with bricks. It was a sturdy house complete with a fine fireplace and chimney. It looked like it could withstand the strongest winds. The next day, a wolf happened to pass by the lane where the three little pigs lived; and he saw the straw house, and he smelled the pig inside. He thought the pig would make a mighty fine meal and his mouth began to water. So he knocked on the door and said:'\n",
        "prob = predictor.predict_proba(sentence)\n",
        "print(prob)\n",
        "np.argmax(prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV3qRPNYjaHE"
      },
      "outputs": [],
      "source": [
        "\n",
        "prob = predictor.get_classes()\n",
        "print(prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhG69-y30uW4"
      },
      "source": [
        "#SAVING OUTPUTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdkU8sjH0toh"
      },
      "outputs": [],
      "source": [
        "# save pipe.pkl to output data folder\n",
        "!cp pipe.pkl /content/drive/MyDrive/Minor/Output/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Cu6jofj4I9jz",
        "s7OE3TnYLUL2"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6fad173c1fc49d8a1d0d75bb69d9377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be1c4222519946f5aed2797aae00d143",
              "IPY_MODEL_5e7ee55dd21d4e9a81063ebdd0b5216c",
              "IPY_MODEL_18de9987698f4de8992e2a863f805ec8"
            ],
            "layout": "IPY_MODEL_e2980a8d431b4ab09e4dcd0043fb548c"
          }
        },
        "be1c4222519946f5aed2797aae00d143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d8bf94724c745a79f1721445d18a6dc",
            "placeholder": "​",
            "style": "IPY_MODEL_3600e11e76274e2e9f1457aa7fac3580",
            "value": "config.json: 100%"
          }
        },
        "5e7ee55dd21d4e9a81063ebdd0b5216c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e8d4b2fa13c4f51abb71459110770ce",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b28d7b91170144278ce2c82744a9c9fc",
            "value": 483
          }
        },
        "18de9987698f4de8992e2a863f805ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0d037f1d3e74f628b730797d10c715d",
            "placeholder": "​",
            "style": "IPY_MODEL_50658b05a7ac422eb738bff8e4acaec1",
            "value": " 483/483 [00:00&lt;00:00, 25.1kB/s]"
          }
        },
        "e2980a8d431b4ab09e4dcd0043fb548c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d8bf94724c745a79f1721445d18a6dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3600e11e76274e2e9f1457aa7fac3580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e8d4b2fa13c4f51abb71459110770ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b28d7b91170144278ce2c82744a9c9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0d037f1d3e74f628b730797d10c715d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50658b05a7ac422eb738bff8e4acaec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bea75e877fda4f4ca71f6cb8433bd096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0501e82a58004ee3a530a8dff2bebe62",
              "IPY_MODEL_11bea714c5254ffdacf6b2cd06b75c73",
              "IPY_MODEL_38627e44b7e94e6dafbea30f22f6ad16"
            ],
            "layout": "IPY_MODEL_b511a2f15be14626bf1cd47d5bae56a5"
          }
        },
        "0501e82a58004ee3a530a8dff2bebe62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_132e7669bf934e628b1582a5d5bafcdf",
            "placeholder": "​",
            "style": "IPY_MODEL_fca740794a534e47875a2384e96a1945",
            "value": "model.safetensors: 100%"
          }
        },
        "11bea714c5254ffdacf6b2cd06b75c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b063e6507f1046e6bbd705af9f20b572",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8aa25f41bb74ddaa01f333ca9b0581b",
            "value": 267954768
          }
        },
        "38627e44b7e94e6dafbea30f22f6ad16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3608152a3fe54c68871adf67f9d5224b",
            "placeholder": "​",
            "style": "IPY_MODEL_5ce42c931ac54514a438677bc59ce452",
            "value": " 268M/268M [00:03&lt;00:00, 39.9MB/s]"
          }
        },
        "b511a2f15be14626bf1cd47d5bae56a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "132e7669bf934e628b1582a5d5bafcdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fca740794a534e47875a2384e96a1945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b063e6507f1046e6bbd705af9f20b572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8aa25f41bb74ddaa01f333ca9b0581b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3608152a3fe54c68871adf67f9d5224b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ce42c931ac54514a438677bc59ce452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cbaa1bd49cd4660a3748fe97247acf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54ad8df72c58493d96130fbc3be94093",
              "IPY_MODEL_5cf3549491024976b82f6fef9805cd52",
              "IPY_MODEL_ebe371ebf71c43a584a840d345032cff"
            ],
            "layout": "IPY_MODEL_bf243e8202be466c82635f1ae6b7a71d"
          }
        },
        "54ad8df72c58493d96130fbc3be94093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f77e510ce9494260add0a255f5beaae6",
            "placeholder": "​",
            "style": "IPY_MODEL_71344f97edeb40d583be8f17deebc075",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "5cf3549491024976b82f6fef9805cd52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_484cf0dc65344bd28f79434577c19192",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74b5a0362a3c4f4bbb205c77cbe8cb0c",
            "value": 28
          }
        },
        "ebe371ebf71c43a584a840d345032cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81d7fe19439f40daadc567a29521a142",
            "placeholder": "​",
            "style": "IPY_MODEL_1a245cf8b668457cb5805e3f5b035480",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.15kB/s]"
          }
        },
        "bf243e8202be466c82635f1ae6b7a71d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f77e510ce9494260add0a255f5beaae6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71344f97edeb40d583be8f17deebc075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "484cf0dc65344bd28f79434577c19192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b5a0362a3c4f4bbb205c77cbe8cb0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81d7fe19439f40daadc567a29521a142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a245cf8b668457cb5805e3f5b035480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3bdfd4b6bb64d0a9c4e3256d3d55182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69b73f10b2e141d4abd5223c1fc9941e",
              "IPY_MODEL_69c2a79634a14f8a95a939eb5223b9ba",
              "IPY_MODEL_57684074cc3e4bccbf055239f3857ecc"
            ],
            "layout": "IPY_MODEL_293db33e8ec54102a4a9f73963e6239c"
          }
        },
        "69b73f10b2e141d4abd5223c1fc9941e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_501cdfcdcf904721b0961219efbe9886",
            "placeholder": "​",
            "style": "IPY_MODEL_c7736b49d12c4faeb8bc7ae08ff2eaf7",
            "value": "vocab.txt: 100%"
          }
        },
        "69c2a79634a14f8a95a939eb5223b9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c20b92482d84ec4823bbcdd4515abd7",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93975294c6ad45dbb07b7d4862b50e7f",
            "value": 231508
          }
        },
        "57684074cc3e4bccbf055239f3857ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_821c177d83ca42a3951a4457f1fd8d63",
            "placeholder": "​",
            "style": "IPY_MODEL_3e4f59b3f1ea409cb2643a46b6b7eb6a",
            "value": " 232k/232k [00:00&lt;00:00, 4.14MB/s]"
          }
        },
        "293db33e8ec54102a4a9f73963e6239c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "501cdfcdcf904721b0961219efbe9886": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7736b49d12c4faeb8bc7ae08ff2eaf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c20b92482d84ec4823bbcdd4515abd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93975294c6ad45dbb07b7d4862b50e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "821c177d83ca42a3951a4457f1fd8d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e4f59b3f1ea409cb2643a46b6b7eb6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3814affccfc548589c45199456b3280d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3077523b8e66476a8bf8c2adbec6c55d",
              "IPY_MODEL_8cb0edf2d8d547bdae586c4c27991cd1",
              "IPY_MODEL_70a8b6225d8d4d908100092571bb6c4f"
            ],
            "layout": "IPY_MODEL_c417ac6f48754a13be42da4a8dae68fd"
          }
        },
        "3077523b8e66476a8bf8c2adbec6c55d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf50ddd201a748ba97cddbf051973809",
            "placeholder": "​",
            "style": "IPY_MODEL_02d73ebe81fa4381940b3dc653663069",
            "value": "tokenizer.json: 100%"
          }
        },
        "8cb0edf2d8d547bdae586c4c27991cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c1a25d5012a4cf0bc8b910fd3331405",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42d4d865b5974b0c936adbea15ccc122",
            "value": 466062
          }
        },
        "70a8b6225d8d4d908100092571bb6c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5a42fc4a0694beeb1875769c5dbf7ea",
            "placeholder": "​",
            "style": "IPY_MODEL_ee56714955d7452e8aeaf2a863cd3957",
            "value": " 466k/466k [00:00&lt;00:00, 10.7MB/s]"
          }
        },
        "c417ac6f48754a13be42da4a8dae68fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf50ddd201a748ba97cddbf051973809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02d73ebe81fa4381940b3dc653663069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c1a25d5012a4cf0bc8b910fd3331405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42d4d865b5974b0c936adbea15ccc122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5a42fc4a0694beeb1875769c5dbf7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee56714955d7452e8aeaf2a863cd3957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}